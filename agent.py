import os
from typing import Annotated
from typing_extensions import TypedDict
from dotenv import load_dotenv

from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages

from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage

# 1. Load biáº¿n mÃ´i trÆ°á»ng (.env chá»©a OPENAI_API_KEY)
load_dotenv()

# 2. Khá»Ÿi táº¡o LLM (GPT-4.1)
llm = init_chat_model("openai:gpt-4.1")

# 3. Äá»‹nh nghÄ©a tráº¡ng thÃ¡i LangGraph
class State(TypedDict):
    messages: Annotated[list, add_messages]

# 4. Äá»‹nh nghÄ©a node "chatbot"
def chatbot(state: State):
    return {"messages": [llm.invoke(state["messages"])]}

# 5. Táº¡o Ä‘á»“ thá»‹ tráº¡ng thÃ¡i
graph_builder = StateGraph(State)

# 6. ThÃªm node "chatbot"
graph_builder.add_node("chatbot", chatbot)

# âœ… 7. ThÃªm entry point â†’ cháº¡y tá»« START Ä‘áº¿n chatbot
graph_builder.add_edge(START, "chatbot")

# âœ… 8. ThÃªm exit point â†’ káº¿t thÃºc sau chatbot
graph_builder.add_edge("chatbot", END)

# âœ… 9. Compile Ä‘á»“ thá»‹ thÃ nh graph cÃ³ thá»ƒ gá»i
graph = graph_builder.compile()

# 10. Cháº¡y thá»­ má»™t láº§n
if __name__ == "__main__":
    user_input = input("Báº¡n: ")
    result = graph.invoke({"messages": [HumanMessage(content=user_input)]})
    print("ğŸ¤– GPT-4.1:", result["messages"][-1].content)
